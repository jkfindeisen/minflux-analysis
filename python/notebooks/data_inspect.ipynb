{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fc083e03",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some imports\n",
    "import sys\n",
    "import os, glob\n",
    "from mfx.processlocalizations import ProcessLocalizations\n",
    "import re\n",
    "from matplotlib import pyplot as plt\n",
    "import math\n",
    "import numpy as np\n",
    "from mfx import mfxcolnames as col\n",
    "import numpy as np\n",
    "import plotly\n",
    "import plotly.express as px\n",
    "import pandas as pd \n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ac84d529",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fig_mean_tids(indict, idx_tids, title, color = False, axis_min = [0,0,0], axis_max = [1,1,1]):\n",
    "    color_map = {-1:'gray', 0: 'blue', 1: 'magenta', 2: 'cyan'}\n",
    "    concat_array= None\n",
    "    for tid in idx_tids:\n",
    "        idx = (indict[col.TID] == tid)\n",
    "        uid = np.unique(indict[col.CLS_TRACK][idx])\n",
    "        pos = indict[col.LTR][idx]\n",
    "        cls = indict[col.CLS_TRACK][idx]\n",
    "        for id_cls in uid:\n",
    "            if id_cls == -1:\n",
    "                continue\n",
    "            m = np.mean(pos[cls==id_cls], axis = 0)\n",
    "            sd = np.std(pos[cls==id_cls], axis = 0)\n",
    "            sd = math.sqrt(np.mean(sd**2))\n",
    "            nl = np.size(pos[cls==id_cls], axis = 0)\n",
    "            se = sd/math.sqrt(nl)\n",
    "            mean_pos_tid = np.append(m, [sd, se, nl, id_cls, tid])\n",
    "            \n",
    "            if concat_array is None:\n",
    "                concat_array = mean_pos_tid\n",
    "            else:\n",
    "                concat_array = np.vstack([concat_array, mean_pos_tid])\n",
    "    df = pd.DataFrame(concat_array, columns = ['x', 'y', 'z', 'sd', 'se', 'nl', 'CLS_TRACK', 'TID'] )  \n",
    "    df.CLS_TRACK = pd.Categorical(df.CLS_TRACK)\n",
    "    fig = px.scatter_3d(df, x='x', y='y',  z = 'z', color = 'CLS_TRACK', symbol = 'TID',\n",
    "                        color_discrete_map=color_map)\n",
    "    fig.update_traces(marker = dict(size = 2, line=dict(width=2,\n",
    "                                        color='DarkSlateGrey')), showlegend=False)\n",
    "    fig.update_layout(scene_aspectmode='cube', \n",
    "                      plot_bgcolor='rgba(0,0,0,0)', paper_bgcolor='rgba(0,0,0,0)', \n",
    "                      scene = dict(\n",
    "                          xaxis = dict(range=[axis_min[0],axis_max[0]]),\n",
    "                          yaxis = dict( range=[axis_min[1],axis_max[1]]),\n",
    "                          zaxis = dict( range=[axis_min[2],axis_max[2]])))\n",
    "    camera = dict(\n",
    "        eye=dict(x=1.25, y=3, z=1.25)\n",
    "    )\n",
    "\n",
    "\n",
    "\n",
    "    fig.update_layout(scene_camera=camera)\n",
    "    return fig\n",
    "\n",
    "def fig_tids(indict, idx_tids, title, color = False):\n",
    "    color_map = {-1:'gray', 0: 'blue', 1: 'magenta', 2: 'cyan'}\n",
    "    df_all = None\n",
    "    print(color_map)\n",
    "    for tid in idx_tids:\n",
    "        idx = (indict[col.TID] == tid)\n",
    "        pos = indict[col.LTR][idx]\n",
    "        axis_min = np.min(pos, axis = 0)\n",
    "        axis_max = np.max(pos, axis = 0)\n",
    "        concat_array = np.insert(indict[col.LTR][idx], 3, \n",
    "                                 indict[col.CLS_TRACK][idx], axis = 1)\n",
    "        concat_array = np.insert(concat_array, 4, indict[col.TID][idx], axis = 1)\n",
    "\n",
    "        df = pd.DataFrame(concat_array, columns=['x', 'y', 'z', 'CLS_TRACK', 'TID'])\n",
    "        \n",
    "        if df_all is None:\n",
    "            df_all = df\n",
    "            axis_min_all = axis_min\n",
    "            axis_max_all = axis_max\n",
    "        else:\n",
    "            axis_min_all = np.min([axis_min_all, axis_min], axis = 0)\n",
    "            axis_max_all = np.max([axis_max_all, axis_max], axis = 0)\n",
    "            \n",
    "            df_all = df_all.append(df)\n",
    "    axis_min_all = axis_min_all - 0.02*axis_min_all\n",
    "    axis_max_all = axis_max_all + 0.02*axis_max_all\n",
    "    \n",
    "    print(axis_min_all)\n",
    "    df_all.CLS_TRACK = pd.Categorical(df_all.CLS_TRACK)\n",
    "    if color:\n",
    "        fig = px.scatter_3d(df_all, x='x', y='y',  z = 'z', \n",
    "                            color = 'CLS_TRACK', symbol = 'TID', \n",
    "               color_discrete_map=color_map)\n",
    "        fig.update_traces(marker = dict(size = 2, line=dict(width=2,\n",
    "                                        color='DarkSlateGrey')), showlegend=False)\n",
    "        \n",
    "    else:\n",
    "        fig = px.scatter_3d(df_all, x='x', y='y',  z = 'z', \n",
    "                           symbol = 'TID')\n",
    "        fig.update_traces(marker = dict(size = 2, color = 'white', \n",
    "                                   line=dict(width=2,\n",
    "                                        color='DarkSlateGrey')), showlegend=False)\n",
    "        \n",
    "    \n",
    "    fig.update_layout(scene_aspectmode='cube', \n",
    "                      plot_bgcolor='rgba(0,0,0,0)', paper_bgcolor='rgba(0,0,0,0)', \n",
    "                      scene = dict(\n",
    "                          xaxis = dict(range=[axis_min_all[0],axis_max_all[0]]),\n",
    "                          yaxis = dict( range=[axis_min_all[1],axis_max_all[1]]),\n",
    "                          zaxis = dict( range=[axis_min_all[2],axis_max_all[2]])))\n",
    "    camera = dict(\n",
    "        eye=dict(x=1.25, y=3, z=1.25)\n",
    "    )\n",
    "\n",
    "\n",
    "    fig.update_layout(scene_camera=camera)\n",
    "    return [fig, axis_min_all, axis_max_all]\n",
    "    \n",
    "\n",
    "def get_random_tids_toplot(tid_splits, nr_samples = 2):\n",
    "    keys = list(tid_splits.keys())\n",
    "    tids_to_plot = list() \n",
    "    #dict(zip(keys, []*len(keys)))\n",
    "    for label in keys:\n",
    "        tid_splits[label].sort(key=lambda x:x[1], reverse=True)\n",
    "        l = len(tid_splits[label])\n",
    "        borders = [[0, round(l/3)],[round(l/3)+1, round(2*l/3)],[round(2*l/3), l]  ]\n",
    "        idx_to_plots = [random.sample(range(x[0],x[1]), nr_samples) for x in borders]\n",
    "        tids = [x[0] for x in tid_splits[label]]\n",
    "        tids_to_plot.append([[tids[idx] for idx in tier] for tier in idx_to_plots])\n",
    "    return tids_to_plot\n",
    "    \n",
    "def show_tids_set(indict, tid_splits, tids_to_plot_in = None, \n",
    "                  postfix   = '', wash = None, color = True, savedir = None):\n",
    "    \n",
    "    keys = list(tid_splits.keys())\n",
    "    if tids_to_plot_in is None:\n",
    "        tids_to_plot = get_tids_toplot(tid_splits)\n",
    "    else:    \n",
    "        tids_to_plot = tids_to_plot_in\n",
    "    if wash == None:\n",
    "        wash = [0,1]\n",
    "    for ikey in wash:\n",
    "        for tier in tids_to_plot[ikey]:\n",
    "            title = '%s, TIDs %s, %s' % (keys[ikey],  ' '.join(map(str, tier)), postfix)\n",
    "            [fig, axis_min, axis_max] = fig_tids(indict[keys[ikey]], tier, title = title, color=color)\n",
    "            fig.show()\n",
    "            fig2 = fig_mean_tids(indict[keys[ikey]], tier, title = title, color=color, axis_min=axis_min, axis_max=axis_max)\n",
    "            fig2.show()\n",
    "            \n",
    "            if savedir is not None:\n",
    "                imgname = os.path.join(savedir, '%s_TID%s_%s.pdf' % (keys[ikey],  '_'.join(map(str, tier)), postfix))\n",
    "                fig.write_image(imgname, format='pdf')\n",
    "                imgname = os.path.join(savedir, '%s_TID%s_%s_meanTID.pdf' % (keys[ikey],  '_'.join(map(str, tier)), postfix))\n",
    "                fig2.write_image(imgname, format='pdf')\n",
    "                \n",
    "            \n",
    "    return tids_to_plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1384df0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get file names\n",
    "\n",
    "def gen_directories( maindir, subdir, keys):\n",
    "    outdir = {}\n",
    "    for key in keys:\n",
    "        outdir[key] = os.path.join(maindir, subdir, key)\n",
    "    return outdir\n",
    "\n",
    "def gen_npyfiles(dir_dict):\n",
    "    npy_files = {}\n",
    "    for key in dir_dict:\n",
    "        npy_files[key] = []\n",
    "\n",
    "    for key in dir_dict:\n",
    "        for (root, dirs, files) in os.walk(dir_dict[key]):\n",
    "            if len(dirs) > 0:\n",
    "                for adir in dirs:\n",
    "                    npyfile = os.path.join(root, adir, adir +'.npy')\n",
    "                    if os.path.exists(npyfile):\n",
    "                        npy_files[key].append(npyfile)\n",
    "                    \n",
    "    return npy_files\n",
    "\n",
    "\n",
    "OUTDIR_LOC = 'C:/Users/apoliti/Desktop/mflux_zarr_tmp_storage/analysis' # Main directory to store zarr files\n",
    "OUTDIR_REM =  'Z:/siva_minflux/analysis'  # Main directory to store results \n",
    "INDIR  = 'Z:/siva_minflux/data'       # main directory of msr file\n",
    "\n",
    "# Multiple washes with different imager strand\n",
    "keys = ['Syp_ATG9', 'ZnT3_Syp', 'Syp_Picc']\n",
    "indir_mwash = gen_directories(INDIR, 'Multiwash', keys)\n",
    "outdir_mwash = gen_directories(OUTDIR_REM, 'Multiwash', keys)\n",
    "zarrdir_mwash = gen_directories(OUTDIR_LOC, 'Multiwash', keys) \n",
    "npy_mwash = gen_npyfiles(outdir_mwash)\n",
    "\n",
    "# Wash with a single imager strand\n",
    "keys = ['Syp', 'ATG9', 'VGLUT1']\n",
    "indir_swash =  gen_directories(INDIR, 'Single wash', keys)\n",
    "outdir_swash =  gen_directories(OUTDIR_REM, 'Single wash', keys)\n",
    "zarrdir_swash =  gen_directories(OUTDIR_LOC, 'Single wash', keys)\n",
    "npy_swash = gen_npyfiles(outdir_swash)\n",
    "\n",
    "\n",
    "# Consitency controls. Wash with a single imager strand but multiple times. \n",
    "keys = ['VGLUT1_VGLUT1']\n",
    "indir_cwash =  gen_directories(INDIR, 'Multiwash', keys)\n",
    "outdir_cwash = gen_directories(OUTDIR_REM, 'Multiwash', keys)\n",
    "zarrdir_cwash = gen_directories(OUTDIR_LOC, 'Multiwash', keys) \n",
    "npy_cwash = gen_npyfiles(outdir_cwash)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e99fc979",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[38;5;39m2022-10-06 10:45:58,190 [INFO] **** trim_min_localizations ****\n",
      "220309_ZnT3_P1 Removed 81/361 tracks with less than 3 localizations\n",
      "220309_Syp_P2 Removed 233/725 tracks with less than 3 localizations\n",
      "\u001b[0m\n",
      "\u001b[38;5;39m2022-10-06 10:46:00,385 [INFO] **** cluster_tid ****\n",
      "220309_ZnT3_P1 MIN_SPLIT_LOCALIZATION: 6, sd_limit: 11.45 nm\n",
      "Processed TID: 21 / 280, Total tracks TID2: 289\n",
      "220309_Syp_P2 MIN_SPLIT_LOCALIZATION: 6, sd_limit: 11.45 nm\n",
      "Processed TID: 41 / 492, Total tracks TID2: 501\n",
      "\u001b[0m\n",
      "\u001b[38;5;39m2022-10-06 10:46:00,531 [INFO] **** trim_min_localizations ****\n",
      "220309_ZnT3_P1 Removed 81/361 tracks with less than 3 localizations\n",
      "220309_Syp_P2 Removed 233/725 tracks with less than 3 localizations\n",
      "\u001b[0m\n",
      "\u001b[38;5;39m2022-10-06 10:46:03,877 [INFO] **** cluster_tid ****\n",
      "220309_ZnT3_P1 MIN_SPLIT_LOCALIZATION: 6, sd_limit: 11.45 nm\n",
      "Processed TID: 21 / 280, Total tracks TID2: 297\n",
      "220309_Syp_P2 MIN_SPLIT_LOCALIZATION: 6, sd_limit: 11.45 nm\n",
      "Processed TID: 41 / 492, Total tracks TID2: 528\n",
      "\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "pl = ProcessLocalizations(npy_mwash['ZnT3_Syp'][1])\n",
    "pl.STD_QUANTILE = 0.9\n",
    "pl.MIN_LOCALIZATIONS = 3\n",
    "pl.DBCLUSTER_SIZE = 3\n",
    "pl.trim_min_localizations()\n",
    "\n",
    "# Split tracks if needed, remove outliers in each track\n",
    "pl.DBCLUSTER_EPS_TRACK = 1.5e-8\n",
    "\n",
    "pl.cluster_tid(method=pl.CLS_METHOD_DBSCAN)\n",
    "#pl.cluster_tid(method=pl.CLS_METHOD_BAYES_GMM, weight_prior = 1e-3)\n",
    "\n",
    "tid_splits_dbscan = pl.get_split_events()\n",
    "loc_dbscan = pl.loc.copy()\n",
    "\n",
    "\n",
    "pl = ProcessLocalizations(npy_mwash['ZnT3_Syp'][1])\n",
    "pl.STD_QUANTILE = 0.9\n",
    "pl.MIN_LOCALIZATIONS = 3\n",
    "pl.DBCLUSTER_SIZE = 3\n",
    "pl.trim_min_localizations()\n",
    "#pl.cluster_tid(method=pl.CLS_METHOD_DBSCAN)\n",
    "pl.cluster_tid(method=pl.CLS_METHOD_BAYES_GMM, weight_prior = 1)\n",
    "tid_splits_bayes_gmm = pl.get_split_events()\n",
    "loc_bayes_gmm = pl.loc.copy()\n",
    "summary_tid = pl.summary_per_tid2()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "114ad8d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show how localizations in TIDs are merged\n",
    "random.seed(15) # to ensure to show the same graph\n",
    "tids_in = get_random_tids_toplot(tid_splits_dbscan)\n",
    "tids_in = [[x[0]] for x in tids_in]\n",
    "savedir = os.path.dirname(os.path.dirname(npy_mwash['ZnT3_Syp'][1]))\n",
    "savedir = os.path.join(savedir, 'figures')\n",
    "#show_tids_set(loc_dbscan, tid_splits_dbscan, tids_to_plot_in=tids_in, \n",
    "#              postfix = 'dbscan_nocolor', wash = [0], color = False, savedir = savedir)\n",
    "show_tids_set(loc_bayes_gmm, tid_splits_bayes_gmm, tids_to_plot_in=tids_in, \n",
    "              postfix = 'bayes_gmm_nocolor', wash = [0], color = False, savedir = savedir)\n",
    "show_tids_set(loc_bayes_gmm, tid_splits_bayes_gmm, tids_to_plot_in=tids_in, \n",
    "              postfix = 'bayes_gmm', wash = [0], color = True, savedir = savedir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dd7d5b73",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 90,  76, 100, ...,  53, 140,  61])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pl.loc['220309_ZnT3_P1']['eco']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f2d16ec5",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'ProcessLocalizations' object has no attribute 'mfx_all'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Input \u001b[1;32mIn [9]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mpl\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmfx_all\u001b[49m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'ProcessLocalizations' object has no attribute 'mfx_all'"
     ]
    }
   ],
   "source": [
    "pl['']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "841b2e00",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:minflux-analysis]",
   "language": "python",
   "name": "conda-env-minflux-analysis-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
