{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2ffcead5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some imports\n",
    "import sys\n",
    "import os, glob\n",
    "from mfx.processlocalizations import ProcessLocalizations\n",
    "import re\n",
    "from matplotlib import pyplot as plt\n",
    "import math\n",
    "import numpy as np\n",
    "from mfx import mfxcolnames as col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3c95dff1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[38;5;39m2022-09-21 22:29:10,845 [INFO] **** log_parameters ****\n",
      "file_path Z:/siva_minflux/analysis//Multiwash/VGLUT1_VGLUT1/220811_VGLUT1_ROI01_First\\220811_VGLUT1_ROI01_First.npy\n",
      "MIN_LOCALIZATIONS 3\n",
      "FACT_SPLIT_LOCALIZATIONS 2\n",
      "DBCLUSTER_SIZE 3\n",
      "DBCLUSTER_EPS_TRACK 2e-08\n",
      "DBCLUSTER_EPS_MEAS 2e-08\n",
      "DBCLUSTER_EPS_ALL 2e-08\n",
      "DBCLUSTER_EPS_MERGED_ALL 2e-08\n",
      "DBCLUSTER_EPS_MERGED_MEAS 2e-08\n",
      "logger <Logger processlocalizations (INFO)>\n",
      "\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# Get file names\n",
    "\n",
    "OUTDIR_LOC = 'C:/Users/apoliti/Desktop/mflux_zarr_tmp_storage/analysis/' # Main directory to store zarr files\n",
    "OUTDIR_REM =  'Z:/siva_minflux/analysis/'  # Main directory to store results \n",
    "INDIR  = 'Z:/siva_minflux/data/'       # main directory of msr file\n",
    "\n",
    "# Multiple washes with different imager strand\n",
    "indir_mwash = {'Syp_ATG9': INDIR + '/Multiwash/Syp_ATG9/', \n",
    "             'ZnT3_Syp': INDIR + '/Multiwash/ZnT3_Syp/'}\n",
    "outdir_mwash = {'Syp_ATG9': OUTDIR_REM +  '/Multiwash/Syp_ATG9/', \n",
    "                'ZnT3_Syp': OUTDIR_REM +  '/Multiwash/ZnT3_Syp/'}\n",
    "zarrdir_mwash = {'Syp_ATG9': OUTDIR_LOC + '/Multiwash/Syp_ATG9', \n",
    "                'ZnT3_Syp': OUTDIR_LOC + '/Multiwash/ZnT3_Syp/'}\n",
    "\n",
    "# Wash with a single imager strand\n",
    "indir_swash = {'Syp': INDIR + '/Single wash/Syp/', \n",
    "             'ATG9': INDIR + '/Single wash/ATG9/'}\n",
    "outdir_swash = {'Syp': OUTDIR_REM +  '/Single wash/Syp/', \n",
    "                'ATG9': OUTDIR_REM +  '/Single wash/ATG9/'}\n",
    "zarrdir_swash = {'Syp': OUTDIR_LOC +  '/Single wash/Syp/', \n",
    "                'ATG9': OUTDIR_LOC +  '/Single wash/ATG9/'}\n",
    "\n",
    "\n",
    "# Consitency controls. Wash with a single imager strand but multiple times. \n",
    "indir_cwash = {'VGLUT1_VGLUT1': INDIR + '/Multiwash/VGLUT1_VGLUT1/'}\n",
    "outdir_cwash = {'VGLUT1_VGLUT1': OUTDIR_REM +  '/Multiwash/VGLUT1_VGLUT1/'}\n",
    "zarrdir_cwash = {'VGLUT1_VGLUT1': OUTDIR_LOC +  '/Multiwash/VGLUT1_VGLUT1/'}\n",
    "\n",
    "\n",
    "\n",
    "npy_mwash = {'Syp_ATG9': [], 'ZnT3_Syp': []}\n",
    "\n",
    "for key in outdir_mwash:\n",
    "    for (root, dirs, files) in os.walk(outdir_mwash[key]):\n",
    "        if len(dirs) > 0:\n",
    "            for adir in dirs:\n",
    "                npyfile = os.path.join(root, adir, adir +'.npy')\n",
    "                if os.path.exists(npyfile):\n",
    "                    npy_mwash[key].append(npyfile)\n",
    "                    \n",
    "\n",
    "npy_swash = {'Syp': [], 'ATG9': []}\n",
    "\n",
    "for key in outdir_swash:\n",
    "    for (root, dirs, files) in os.walk(outdir_swash[key]):\n",
    "        if len(dirs) > 0:\n",
    "            for adir in dirs:\n",
    "                npyfile = os.path.join(root, adir, adir +'.npy')\n",
    "                if os.path.exists(npyfile):\n",
    "                    npy_swash[key].append(npyfile)\n",
    "\n",
    "npy_cwash = {'VGLUT1_VGLUT1': []}\n",
    "\n",
    "for key in outdir_cwash:\n",
    "    for (root, dirs, files) in os.walk(outdir_cwash[key]):\n",
    "        if len(dirs) > 0:\n",
    "            for adir in dirs:\n",
    "                npyfile = os.path.join(root, adir, adir +'.npy')\n",
    "                if os.path.exists(npyfile):\n",
    "                    npy_cwash[key].append(npyfile)\n",
    "\n",
    "pl = ProcessLocalizations(npy_cwash['VGLUT1_VGLUT1'][1])\n",
    "pl.log_parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c23abe67",
   "metadata": {},
   "outputs": [],
   "source": [
    "def processFile(file_name, eps_range):\n",
    "    pl = ProcessLocalizations(file_name)\n",
    "    pl.trim_min_localizations()\n",
    "    # Split tracks if needed, remove outliers in each track\n",
    "    pl.cluster_tid(method=pl.CLS_METHOD_BAYES_GMM)\n",
    "\n",
    "    # find objects that belong to the same cluster according to distance 30 nm\n",
    "    for eps in eps_range:\n",
    "            \n",
    "        pl.DBCLUSTER_EPS_MEAS = eps\n",
    "        pl.DBCLUSTER_EPS_ALL = eps\n",
    "        pl.DBCLUSTER_EPS_MERGED_ALL = eps\n",
    "        pl.DBCLUSTER_EPS_MERGED_MEAS = eps\n",
    "        pl.log_parameters()\n",
    "    \n",
    "        pl.cluster_meas(method=pl.CLS_METHOD_DBSCAN)\n",
    "        pl.cluster_all(method=pl.CLS_METHOD_DBSCAN)\n",
    "        pl.cluster_all_intersect(col.CLS_ALL)\n",
    "        summary_dict = pl.summary_per_tid2()\n",
    "        pl.cluster_meas(method=pl.CLS_METHOD_DBSCAN)\n",
    "        pl.cluster_all(method=pl.CLS_METHOD_DBSCAN)\n",
    "        pl.cluster_all_intersect(col.CLS_ALL)\n",
    "        summary_dict = pl.summary_per_tid2()\n",
    "        eps_txt = '%d' % (eps*1e9)\n",
    "        pl.export_csv(summary_dict, file_path=pl.file_path_no_ext() + '_eps' + eps_txt)\n",
    "        pl.export_vtu(in_dict=summary_dict, coord=col.LTR, file_path=pl.file_path_no_ext() + '_eps' +  eps_txt)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "968de0c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[38;5;39m2022-09-21 22:31:41,290 [INFO] **** trim_min_localizations ****\n",
      "220825_Syp_P1 Removed 281/1354 tracks with less than 3 localizations\n",
      "\u001b[0m\n",
      "\u001b[38;5;39m2022-09-21 22:31:53,523 [INFO] **** cluster_tid ****\n",
      "220825_Syp_P1 MIN_SPLIT_LOCALIZATION: 6, sd_limit: 10.03 nm\n",
      "Processed TID: 228 / 1073, Total tracks TID2: 1208\n",
      "\u001b[0m\n",
      "\u001b[38;5;39m2022-09-21 22:31:53,525 [INFO] **** log_parameters ****\n",
      "file_path Z:/siva_minflux/analysis//Single wash/Syp/220825_Syp_ROI2\\220825_Syp_ROI2.npy\n",
      "MIN_LOCALIZATIONS 3\n",
      "FACT_SPLIT_LOCALIZATIONS 2\n",
      "DBCLUSTER_SIZE 3\n",
      "DBCLUSTER_EPS_TRACK 2e-08\n",
      "DBCLUSTER_EPS_MEAS 2e-09\n",
      "DBCLUSTER_EPS_ALL 2e-09\n",
      "DBCLUSTER_EPS_MERGED_ALL 2e-09\n",
      "DBCLUSTER_EPS_MERGED_MEAS 2e-09\n",
      "logger <Logger processlocalizations (INFO)>\n",
      "\u001b[0m\n",
      "\u001b[38;5;39m2022-09-21 22:31:53,724 [INFO] **** cluster_meas ****\n",
      "220825_Syp_P1, Method dbscan, eps: 2.00 nm\n",
      "Total tracks TID2: 1207, total clusters meas: 1207\n",
      "\u001b[0m\n",
      "\u001b[38;5;39m2022-09-21 22:31:53,734 [INFO] **** cluster_all ****\n",
      "*******cluster_all*******\n",
      "Only one wash. Nothing to do\u001b[0m\n",
      "\u001b[38;5;39m2022-09-21 22:31:53,736 [INFO] **** cluster_all_intersect ****\n",
      "Only one wash\u001b[0m\n",
      "export csv table\n",
      "export paraview file\n",
      "\u001b[38;5;39m2022-09-21 22:31:54,950 [INFO] **** cluster_meas ****\n",
      "220825_Syp_P1, Method dbscan, eps: 2.00 nm\n",
      "Total tracks TID2: 1207, total clusters meas: 1207\n",
      "\u001b[0m\n",
      "\u001b[38;5;39m2022-09-21 22:31:54,953 [INFO] **** cluster_all ****\n",
      "*******cluster_all*******\n",
      "Only one wash. Nothing to do\u001b[0m\n",
      "\u001b[38;5;39m2022-09-21 22:31:54,955 [INFO] **** cluster_all_intersect ****\n",
      "Only one wash\u001b[0m\n",
      "export csv table\n",
      "export paraview file\n"
     ]
    }
   ],
   "source": [
    "eps_range = [5e-9, 1e-8, 2e-8, 3e-8, 4e-8, 5e-8, 1e-7]\n",
    "processFile(npy_swash['Syp'][0], eps_range=[2e-9])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a9363ce6",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pl' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [1]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28msum\u001b[39m(\u001b[43mpl\u001b[49m\u001b[38;5;241m.\u001b[39mloc[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m220825_Syp_P1\u001b[39m\u001b[38;5;124m'\u001b[39m][col\u001b[38;5;241m.\u001b[39mTID2] \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'pl' is not defined"
     ]
    }
   ],
   "source": [
    "sum(pl.loc['220825_Syp_P1'][col.TID2] == -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a4e57ee3",
   "metadata": {},
   "outputs": [],
   "source": [
    "eps_txt = '%d' % (eps*1e9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa2186c3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4891eb6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:minflux-analysis]",
   "language": "python",
   "name": "conda-env-minflux-analysis-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
